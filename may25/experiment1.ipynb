{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Automated Code Smell Detection Using Large Language Models\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Code smells - patterns in source code that indicate potential design problems - are critical indicators of software quality issues. Traditionally, identifying code smells has relied on:\n",
    "\n",
    "1. Manual code reviews (time-consuming and subjective)\n",
    "2. Static analysis tools (limited to predefined patterns)\n",
    "3. Software metrics (often producing false positives)\n",
    "\n",
    "These approaches either require significant human effort or lack the contextual understanding needed to identify subtle design issues.\n",
    "\n",
    "## How Generative AI Solves This Problem\n",
    "\n",
    "This notebook demonstrates how Large Language Models (LLMs) can transform code smell detection by:\n",
    "\n",
    "- **Contextual understanding**: Analyzing code with deep semantic understanding rather than just pattern matching\n",
    "- **Knowledge integration**: Leveraging structured knowledge about different code smell types and refactoring solutions\n",
    "- **Natural language reasoning**: Providing detailed explanations and actionable recommendations in human-readable format\n",
    "\n",
    "## What This Notebook Demonstrates\n",
    "\n",
    "This end-to-end implementation shows how to:\n",
    "\n",
    "1. Build a knowledge base of code smells using vector embeddings and DeepLake\n",
    "2. Create a retrieval-augmented generation (RAG) system to provide context about code smells\n",
    "3. Analyze Java code files to detect multiple types of code smells\n",
    "4. Generate structured output with smell locations, severity, and refactoring suggestions\n",
    "5. Evaluate detection quality against manually labeled data\n",
    "\n",
    "The approach provides a practical showcase of how generative AI can be applied to enhance software development practices through automated code quality assessment.\n",
    "\n",
    "**Now, let's begin.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*install all needed dependencies:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:44.309246Z",
     "iopub.status.busy": "2025-04-21T04:12:44.308907Z",
     "iopub.status.idle": "2025-04-21T04:12:49.180332Z",
     "shell.execute_reply": "2025-04-21T04:12:49.179219Z",
     "shell.execute_reply.started": "2025-04-21T04:12:44.309221Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: deeplake 3.9.44 does not provide the extra 'enterprise'\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pillow in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (11.2.1)\n",
      "Requirement already satisfied: lz4 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (4.4.4)\n",
      "Requirement already satisfied: python-dotenv in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: sonar-tools in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (3.10)\n",
      "Requirement already satisfied: mysql-connector-python in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (9.3.0)\n",
      "Requirement already satisfied: pandas in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Collecting argparse (from sonar-tools)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: datetime in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from sonar-tools) (5.5)\n",
      "Requirement already satisfied: python-dateutil in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from sonar-tools) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from sonar-tools) (2.32.3)\n",
      "Requirement already satisfied: jprops in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from sonar-tools) (2.0.2)\n",
      "Requirement already satisfied: levenshtein in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from sonar-tools) (0.27.1)\n",
      "Requirement already satisfied: PyYAML in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from sonar-tools) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from python-dateutil->sonar-tools) (1.17.0)\n",
      "Requirement already satisfied: zope.interface in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from datetime->sonar-tools) (7.2)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from levenshtein->sonar-tools) (3.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from requests->sonar-tools) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from requests->sonar-tools) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from requests->sonar-tools) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from requests->sonar-tools) (2025.4.26)\n",
      "Requirement already satisfied: setuptools in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from zope.interface->datetime->sonar-tools) (80.0.0)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U \"langchain-google-genai\" \"deeplake\" \"langchain\" \"langchain-text-splitters\" \"langchain-community\" \"tiktoken\" \"google-ai-generativelanguage==0.6.15\" \"deeplake[enterprise]<4.0.0\"\n",
    "%pip install pillow lz4 python-dotenv sonar-tools mysql-connector-python pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now initialize deep lake vectore store and store structured info about code smells in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use 2 repos as a data sources:\n",
    "\n",
    "* pixel-dungeon - as an example of software that contains numerous code smells.\n",
    "* smells - a comprehensive classification of code smells. we will use structured information about code smells from this repository in our DeepLake database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:49.182543Z",
     "iopub.status.busy": "2025-04-21T04:12:49.182281Z",
     "iopub.status.idle": "2025-04-21T04:12:49.439865Z",
     "shell.execute_reply": "2025-04-21T04:12:49.439005Z",
     "shell.execute_reply.started": "2025-04-21T04:12:49.182518Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pixel-dungeon' already exists and is not an empty directory.\n",
      "fatal: destination path 'smells' already exists and is not an empty directory.\n",
      "fatal: destination path 'arthas' already exists and is not an empty directory.\n",
      "\u001b[34marthas\u001b[m\u001b[m             import pytest.json \u001b[34msmells\u001b[m\u001b[m\n",
      "experiment1.ipynb  \u001b[34mpixel-dungeon\u001b[m\u001b[m\n",
      "HEAD is now at 4fc68226 classloader command support jdk.internal.loader.ClassLoaders$AppClassLoade. #2350\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/watabou/pixel-dungeon.git\n",
    "!git clone https://github.com/Luzkan/smells.git\n",
    "!git clone https://github.com/alibaba/arthas.git\n",
    "!ls\n",
    "!cd ./arthas && git checkout 4fc682265ce9e8db0101f978d32b142af6751493\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all files with structured info about code smells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:49.441348Z",
     "iopub.status.busy": "2025-04-21T04:12:49.441030Z",
     "iopub.status.idle": "2025-04-21T04:12:49.447247Z",
     "shell.execute_reply": "2025-04-21T04:12:49.446321Z",
     "shell.execute_reply.started": "2025-04-21T04:12:49.441321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "import deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a Kaggle secret named GOOGLE_API_KEY.\n",
    "\n",
    "If you don't already have an API key, you can grab one from AI Studio. You can find detailed instructions in the docs.\n",
    "\n",
    "To make the key available through Kaggle secrets, choose Secrets from the Add-ons menu and follow the instructions to add your key or enable it for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:49.449292Z",
     "iopub.status.busy": "2025-04-21T04:12:49.449055Z",
     "iopub.status.idle": "2025-04-21T04:12:49.546729Z",
     "shell.execute_reply": "2025-04-21T04:12:49.546037Z",
     "shell.execute_reply.started": "2025-04-21T04:12:49.449266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:49.547636Z",
     "iopub.status.busy": "2025-04-21T04:12:49.547372Z",
     "iopub.status.idle": "2025-04-21T04:12:49.554060Z",
     "shell.execute_reply": "2025-04-21T04:12:49.553327Z",
     "shell.execute_reply.started": "2025-04-21T04:12:49.547618Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smells implemented in Sonarqube are represented by 4 markdown files:\n",
      "  smells/content/smells/duplicated-code.md\n",
      "  smells/content/smells/long-method.md\n",
      "  smells/content/smells/large-class.md\n",
      "  smells/content/smells/long-parameter-list.md\n"
     ]
    }
   ],
   "source": [
    "#smells_match = \"smells/content/smells/**/*.md\"\n",
    "smell_files = [\n",
    "    \"smells/content/smells/duplicated-code.md\",\n",
    "    \"smells/content/smells/long-method.md\", \n",
    "    \"smells/content/smells/large-class.md\",\n",
    "    \"smells/content/smells/long-parameter-list.md\"\n",
    "]\n",
    "\n",
    "all_smells = []\n",
    "for file_pattern in smell_files:\n",
    "    matches = glob(file_pattern)\n",
    "    all_smells.extend(matches)\n",
    "\n",
    "print(f\"Smells implemented in Sonarqube are represented by {len(all_smells)} markdown files:\")\n",
    "for file in all_smells:\n",
    "    print(f\"  {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file with a matching path will be loaded and split by RecursiveCharacterTextSplitter. only Markdown files with structured content will be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:49.555112Z",
     "iopub.status.busy": "2025-04-21T04:12:49.554842Z",
     "iopub.status.idle": "2025-04-21T04:12:49.571207Z",
     "shell.execute_reply": "2025-04-21T04:12:49.570201Z",
     "shell.execute_reply.started": "2025-04-21T04:12:49.555084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n#{1,6} ',\n",
       " '```\\n',\n",
       " '\\n\\\\*\\\\*\\\\*+\\n',\n",
       " '\\n---+\\n',\n",
       " '\\n___+\\n',\n",
       " '\\n\\n',\n",
       " '\\n',\n",
       " ' ',\n",
       " '']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common seperators used for Python files\n",
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.MARKDOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:49.572620Z",
     "iopub.status.busy": "2025-04-21T04:12:49.572396Z",
     "iopub.status.idle": "2025-04-21T04:12:53.017736Z",
     "shell.execute_reply": "2025-04-21T04:12:53.016592Z",
     "shell.execute_reply.started": "2025-04-21T04:12:49.572599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-frontmatter in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: PyYAML in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from python-frontmatter) (6.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-frontmatter\n",
    "%pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:53.019468Z",
     "iopub.status.busy": "2025-04-21T04:12:53.019170Z",
     "iopub.status.idle": "2025-04-21T04:12:53.054188Z",
     "shell.execute_reply": "2025-04-21T04:12:53.053373Z",
     "shell.execute_reply.started": "2025-04-21T04:12:53.019441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 19 chunks from 4 files\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "\n",
    "# Define headers that match your code smell documentation structure\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Title\"),\n",
    "    (\"##\", \"Section\"),\n",
    "    (\"###\", \"Subsection\")\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for file in all_smells:\n",
    "    try:\n",
    "        # First load the file as text\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract the main content (everything after the frontmatter)\n",
    "        if '---' in content:\n",
    "            # Find the second occurrence of '---' which ends the frontmatter\n",
    "            parts = content.split('---', 2)\n",
    "            if len(parts) >= 3:\n",
    "                markdown_content = '---' + parts[2]  # Keep the separator for proper markdown parsing\n",
    "            else:\n",
    "                markdown_content = content\n",
    "        else:\n",
    "            markdown_content = content\n",
    "            \n",
    "        # Split by markdown headers\n",
    "        markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "        header_splits = markdown_splitter.split_text(markdown_content)\n",
    "        \n",
    "        # Add source file info to metadata\n",
    "        for doc in header_splits:\n",
    "            doc.metadata['source'] = file\n",
    "        \n",
    "        # Add to collection\n",
    "        docs.extend(header_splits)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "print(f\"Created {len(docs)} chunks from {len(all_smells)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:53.055381Z",
     "iopub.status.busy": "2025-04-21T04:12:53.055035Z",
     "iopub.status.idle": "2025-04-21T04:12:53.059560Z",
     "shell.execute_reply": "2025-04-21T04:12:53.058839Z",
     "shell.execute_reply.started": "2025-04-21T04:12:53.055356Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define path to database\n",
    "dataset_path = 'mem://deeplake/smells'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:53.063671Z",
     "iopub.status.busy": "2025-04-21T04:12:53.062806Z",
     "iopub.status.idle": "2025-04-21T04:12:53.078015Z",
     "shell.execute_reply": "2025-04-21T04:12:53.077165Z",
     "shell.execute_reply.started": "2025-04-21T04:12:53.063641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define the embedding model\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:53.079504Z",
     "iopub.status.busy": "2025-04-21T04:12:53.079166Z",
     "iopub.status.idle": "2025-04-21T04:12:58.318953Z",
     "shell.execute_reply": "2025-04-21T04:12:58.318051Z",
     "shell.execute_reply.started": "2025-04-21T04:12:53.079483Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 19 embeddings in 1 batches of size 19:: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='mem://deeplake/smells', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (19, 1)     str     None   \n",
      " metadata     json      (19, 1)     str     None   \n",
      " embedding  embedding  (19, 768)  float32   None   \n",
      "    id        text      (19, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "smell_db = DeepLake.from_documents(docs, embeddings, dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:58.320342Z",
     "iopub.status.busy": "2025-04-21T04:12:58.320099Z",
     "iopub.status.idle": "2025-04-21T04:12:58.324688Z",
     "shell.execute_reply": "2025-04-21T04:12:58.324035Z",
     "shell.execute_reply.started": "2025-04-21T04:12:58.320323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retriever = smell_db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['k'] = 20 # number of documents to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:58.325899Z",
     "iopub.status.busy": "2025-04-21T04:12:58.325600Z",
     "iopub.status.idle": "2025-04-21T04:12:58.343079Z",
     "shell.execute_reply": "2025-04-21T04:12:58.342348Z",
     "shell.execute_reply.started": "2025-04-21T04:12:58.325871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define the chat model\n",
    "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:58.344330Z",
     "iopub.status.busy": "2025-04-21T04:12:58.344040Z",
     "iopub.status.idle": "2025-04-21T04:12:58.360552Z",
     "shell.execute_reply": "2025-04-21T04:12:58.359716Z",
     "shell.execute_reply.started": "2025-04-21T04:12:58.344307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_llm(llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:58.361637Z",
     "iopub.status.busy": "2025-04-21T04:12:58.361393Z",
     "iopub.status.idle": "2025-04-21T04:12:58.375175Z",
     "shell.execute_reply": "2025-04-21T04:12:58.374280Z",
     "shell.execute_reply.started": "2025-04-21T04:12:58.361608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# a helper function for calling retrival chain\n",
    "def call_qa_chain(prompt):\n",
    "  response = qa.invoke(prompt)\n",
    "  display(Markdown(response[\"result\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:12:58.376538Z",
     "iopub.status.busy": "2025-04-21T04:12:58.376144Z",
     "iopub.status.idle": "2025-04-21T04:13:01.054877Z",
     "shell.execute_reply": "2025-04-21T04:13:01.054035Z",
     "shell.execute_reply.started": "2025-04-21T04:12:58.376510Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some refactoring strategies to address the 'Large Class' code smell, ranging from simpler to more complex:\n",
       "\n",
       "1.  **Extract Class**:\n",
       "    *   This involves identifying related responsibilities within the large class and moving them into a new, separate class. This reduces the original class's scope and improves cohesion.\n",
       "2.  **Extract Subclass**:\n",
       "    *   If the large class has behaviors that vary based on certain states or types, creating subclasses can help organize and isolate these variations.\n",
       "3.  **Extract Interface**:\n",
       "    *   When a class implements multiple interfaces, extracting interfaces can help to decouple the class from its dependencies and make it more flexible.\n",
       "4.  **Extract Domain Object**:\n",
       "    *   If the class is dealing with complex data structures or business logic, extracting domain objects can encapsulate this logic and improve the overall design.\n",
       "5.  **Replace Data Value with object**:\n",
       "    *   If a class has a field that is only used by a subset of methods, it may be better to create a new class to hold the field and those methods."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "call_qa_chain(\"List a recommendations on how to get rid of 'God class' smell, rating from more simple to more sophisticated strategies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:01.056074Z",
     "iopub.status.busy": "2025-04-21T04:13:01.055791Z",
     "iopub.status.idle": "2025-04-21T04:13:01.065769Z",
     "shell.execute_reply": "2025-04-21T04:13:01.065016Z",
     "shell.execute_reply.started": "2025-04-21T04:13:01.056047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created enum with 4 code smells:\n",
      "DUPLICATED_CODE = 'duplicated-code'\n",
      "LONG_METHOD = 'long-method'\n",
      "LARGE_CLASS = 'large-class'\n",
      "LONG_PARAMETER_LIST = 'long-parameter-list'\n",
      "\n",
      "Example usage:\n",
      "CodeSmell.LONG_METHOD = 'long-method'\n",
      "CodeSmell.LARGE_CLASS = 'large-class'\n",
      "\n",
      "Looking up by name:\n",
      "get_smell_by_name('long-method') = CodeSmell.LONG_METHOD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import enum\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Get all markdown files in the content/smells directory\n",
    "smell_files = all_smells\n",
    "\n",
    "# Create enum class dynamically\n",
    "def create_code_smell_enum():\n",
    "    # Process each filename to create enum-friendly names\n",
    "    enum_entries = {}\n",
    "    \n",
    "    for file_path in smell_files:\n",
    "        # Extract filename without extension\n",
    "        filename = Path(file_path).stem\n",
    "        \n",
    "        # Convert kebab-case to UPPER_SNAKE_CASE for enum names\n",
    "        enum_name = filename.replace('-', '_').upper()\n",
    "        \n",
    "        # Use the original filename (without extension) as the value\n",
    "        enum_entries[enum_name] = filename\n",
    "    \n",
    "    # Create and return the Enum class\n",
    "    return enum.Enum('CodeSmell', enum_entries)\n",
    "\n",
    "# Create the enum\n",
    "CodeSmell = create_code_smell_enum()\n",
    "\n",
    "# Display the enum members\n",
    "print(f\"Created enum with {len(CodeSmell)} code smells:\")\n",
    "for smell in CodeSmell:\n",
    "    print(f\"{smell.name} = '{smell.value}'\")\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nExample usage:\")\n",
    "print(f\"CodeSmell.LONG_METHOD = '{CodeSmell.LONG_METHOD.value}'\")\n",
    "print(f\"CodeSmell.LARGE_CLASS = '{CodeSmell.LARGE_CLASS.value}'\")\n",
    "\n",
    "# You can also look up an enum by value\n",
    "def get_smell_by_name(name):\n",
    "    for smell in CodeSmell:\n",
    "        if smell.value == name:\n",
    "            return smell\n",
    "    return None\n",
    "\n",
    "print(\"\\nLooking up by name:\")\n",
    "print(f\"get_smell_by_name('long-method') = {get_smell_by_name('long-method')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:01.067146Z",
     "iopub.status.busy": "2025-04-21T04:13:01.066851Z",
     "iopub.status.idle": "2025-04-21T04:13:04.768623Z",
     "shell.execute_reply": "2025-04-21T04:13:04.767719Z",
     "shell.execute_reply.started": "2025-04-21T04:13:01.067126Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-text-splitters in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (0.3.8)\n",
      "Requirement already satisfied: pypdf in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (5.5.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (0.3.60)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (0.3.37)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/havriil.pietukhin/uni/masterThesis/code/smellai/.venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community langchain-text-splitters pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:04.770413Z",
     "iopub.status.busy": "2025-04-21T04:13:04.769977Z",
     "iopub.status.idle": "2025-04-21T04:13:04.785847Z",
     "shell.execute_reply": "2025-04-21T04:13:04.785173Z",
     "shell.execute_reply.started": "2025-04-21T04:13:04.770381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Literal\n",
    "import enum\n",
    "\n",
    "# Define your structured output schema using Pydantic\n",
    "class CodeSmellSeverity(str, enum.Enum):\n",
    "    HIGH = \"HIGH\"\n",
    "    MEDIUM = \"MEDIUM\" \n",
    "    LOW = \"LOW\"\n",
    "\n",
    "class CodeSmellDetection(BaseModel):\n",
    "    smell_type: str = Field(description=\"The type of code smell detected\")\n",
    "    location: str = Field(description=\"Where in the code the smell was found\")\n",
    "    severity: CodeSmellSeverity = Field(description=\"How severe the smell is\")\n",
    "    description: str = Field(description=\"Brief explanation of the issue\")\n",
    "    refactoring_suggestion: str = Field(description=\"How to fix the code smell\")\n",
    "    code_example: Optional[str] = Field(None, description=\"Example code showing the fix\")\n",
    "\n",
    "class CodeAnalysisResult(BaseModel):\n",
    "    analysis_summary: str = Field(description=\"Overall summary of code quality\")\n",
    "    smells_detected: List[CodeSmellDetection] = Field(description=\"List of detected code smells\")\n",
    "\n",
    "# Create a parser for the structured output\n",
    "parser = PydanticOutputParser(pydantic_object=CodeAnalysisResult)\n",
    "\n",
    "# Create a prompt template that includes formatting instructions\n",
    "code_analysis_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an expert code analyst. Analyze the following code for code smells:\n",
    "\n",
    "```java\n",
    "{code}\n",
    "{format_instructions}\n",
    "\n",
    "Only identify code smells from this list: {valid_smells} \"\"\", input_variables=[\"code\", \"valid_smells\"], partial_variables={\"format_instructions\": parser.get_format_instructions()} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:04.787042Z",
     "iopub.status.busy": "2025-04-21T04:13:04.786733Z",
     "iopub.status.idle": "2025-04-21T04:13:04.811802Z",
     "shell.execute_reply": "2025-04-21T04:13:04.811037Z",
     "shell.execute_reply.started": "2025-04-21T04:13:04.787015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def analyze_code_with_structure(code_content):\n",
    "    # Get list of valid smells for reference\n",
    "    valid_smells = \", \".join([smell.name for smell in CodeSmell])\n",
    "    \n",
    "    # Create a prompt that sends the code directly to the QA system\n",
    "    analysis_prompt = f\"\"\"\n",
    "    Analyze the following code for code smells:\n",
    "    \n",
    "    ```java\n",
    "    {code_content}\n",
    "    ```\n",
    "    \n",
    "    What code smells can you identify in this code and why? Only consider these code smell types: {valid_smells}.\n",
    "    \n",
    "    For each smell found, provide:\n",
    "    1. The exact smell type (from the list provided)\n",
    "    2. Location in the code (file, line numbers, method names)\n",
    "    3. Severity (HIGH, MEDIUM, LOW)\n",
    "    4. Description of why this is a code smell\n",
    "    5. Refactoring suggestion to fix the issue\n",
    "    6. Optional: Example code showing the fix\n",
    "    \n",
    "    Format your response as a structured JSON object matching this schema:\n",
    "    {parser.get_format_instructions()}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the QA system which leverages the smell knowledge base\n",
    "    try:\n",
    "        qa_result = qa.invoke(analysis_prompt)\n",
    "        \n",
    "        # Try to extract and parse JSON from the result\n",
    "        output_text = qa_result[\"result\"]\n",
    "        parsed_output = parser.parse(output_text)\n",
    "        return parsed_output\n",
    "    except Exception as e:\n",
    "        print(f\"Error in code smell analysis: {e}\")\n",
    "        print(f\"Raw QA output: {qa_result['result'] if 'qa_result' in locals() else 'No output'}\")\n",
    "        \n",
    "        # Fallback to direct LLM call if QA system parsing fails\n",
    "        try:\n",
    "            direct_output = llm.invoke(analysis_prompt)\n",
    "            parsed_output = parser.parse(direct_output.content)\n",
    "            return parsed_output\n",
    "        except Exception as e2:\n",
    "            print(f\"Fallback also failed: {e2}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:04.813138Z",
     "iopub.status.busy": "2025-04-21T04:13:04.812770Z",
     "iopub.status.idle": "2025-04-21T04:13:04.834522Z",
     "shell.execute_reply": "2025-04-21T04:13:04.833692Z",
     "shell.execute_reply.started": "2025-04-21T04:13:04.813116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def display_code_analysis(file_path): # Read the file content \n",
    "    with open(file_path, 'r') as f: code_content = f.read()\n",
    "        # Analyze the code\n",
    "    analysis = analyze_code_with_structure(code_content)\n",
    "\n",
    "    if not analysis:\n",
    "        print(\"Failed to analyze code.\")\n",
    "        return\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Analysis Summary: {analysis.analysis_summary}\\n\")\n",
    "    print(f\"Detected {len(analysis.smells_detected)} code smells:\")\n",
    "\n",
    "    for i, smell in enumerate(analysis.smells_detected, 1):\n",
    "        print(f\"\\n{i}. {smell.smell_type} ({smell.severity})\")\n",
    "        print(f\"   Location: {smell.location}\")\n",
    "        print(f\"   Description: {smell.description}\")\n",
    "        print(f\"   Refactoring: {smell.refactoring_suggestion}\")\n",
    "        if smell.code_example:\n",
    "            print(f\"\\n   Example fix:\\n   ```\\n{smell.code_example}\\n   ```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:04.835821Z",
     "iopub.status.busy": "2025-04-21T04:13:04.835491Z",
     "iopub.status.idle": "2025-04-21T04:13:22.027498Z",
     "shell.execute_reply": "2025-04-21T04:13:22.026693Z",
     "shell.execute_reply.started": "2025-04-21T04:13:04.835796Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Summary: The code exhibits some code smells related to method length and potential for large class refactoring. Specifically, the `decorate` method and the nested `Stream` class's `update` method could be candidates for refactoring. There's also duplicated code in `tileName` and `tileDesc`.\n",
      "\n",
      "Detected 3 code smells:\n",
      "\n",
      "1. LONG_METHOD (CodeSmellSeverity.MEDIUM)\n",
      "   Location: HallsLevel.java, decorate() method, lines 51-73\n",
      "   Description: The `decorate` method performs multiple operations: decorating empty tiles, decorating wall tiles, and placing a sign. This violates the single responsibility principle and makes the method harder to understand and maintain.\n",
      "   Refactoring: Extract each decoration logic (empty tile decoration, wall decoration, sign placement) into separate methods. This will make the `decorate` method shorter and more focused.\n",
      "\n",
      "2. DUPLICATED_CODE (CodeSmellSeverity.LOW)\n",
      "   Location: HallsLevel.java, tileName() and tileDesc() methods, lines 76-95 and 98-114\n",
      "   Description: Both `tileName` and `tileDesc` methods use similar `switch` statements based on the `tile` parameter. This duplication can lead to inconsistencies if one method is updated and the other is not.\n",
      "   Refactoring: Create a common method that takes the tile type and a flag indicating whether to return the name or description. This centralizes the logic and reduces duplication.\n",
      "\n",
      "3. LONG_METHOD (CodeSmellSeverity.LOW)\n",
      "   Location: HallsLevel.java, Stream.update() method, lines 143-155\n",
      "   Description: The `update` method in the `Stream` class handles visibility checks, calling the super update method, managing delay, and particle spawning. This could be broken down for better readability and maintainability.\n",
      "   Refactoring: Extract the particle spawning logic into a separate method. This simplifies the `update` method and makes it easier to understand.\n"
     ]
    }
   ],
   "source": [
    "# Analyze a Java file from the pixel-dungeon repository\n",
    "java_file = \"pixel-dungeon/src/com/watabou/pixeldungeon/levels/HallsLevel.java\"\n",
    "display_code_analysis(java_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:22.028333Z",
     "iopub.status.busy": "2025-04-21T04:13:22.028134Z",
     "iopub.status.idle": "2025-04-21T04:13:22.049054Z",
     "shell.execute_reply": "2025-04-21T04:13:22.048051Z",
     "shell.execute_reply.started": "2025-04-21T04:13:22.028317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "import enum\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 1. Define evaluation schema\n",
    "class EvaluationScore(str, enum.Enum):\n",
    "    EXCELLENT = \"EXCELLENT\"\n",
    "    GOOD = \"GOOD\"\n",
    "    ACCEPTABLE = \"ACCEPTABLE\"\n",
    "    POOR = \"POOR\"\n",
    "    INCORRECT = \"INCORRECT\"\n",
    "\n",
    "class SmellEvaluation(BaseModel):\n",
    "    detected_smell: str = Field(description=\"The detected code smell type\")\n",
    "    location: str = Field(description=\"Where the smell was detected\")\n",
    "    ground_truth_match: Optional[str] = Field(None, description=\"The matching ground truth smell if any\")\n",
    "    score: EvaluationScore = Field(description=\"Evaluation score for this detection\")\n",
    "    justification: str = Field(description=\"Explanation for the rating\")\n",
    "\n",
    "class CodeSmellEvaluationResult(BaseModel):\n",
    "    overall_score: float = Field(description=\"Overall evaluation score out of 5\")\n",
    "    precision: float = Field(description=\"Ratio of correctly identified smells to all detections\")\n",
    "    recall: float = Field(description=\"Ratio of correctly identified smells to all actual smells\")\n",
    "    evaluations: List[SmellEvaluation] = Field(description=\"Individual smell evaluations\")\n",
    "    summary: str = Field(description=\"Summary of evaluation results\")\n",
    "\n",
    "# 2. Create the evaluation prompt template\n",
    "eval_template = \"\"\"\n",
    "# Instruction\n",
    "You are an expert evaluator specializing in code smell detection. Your task is to evaluate the quality of code smell detections by comparing them with ground truth data.\n",
    "\n",
    "# Evaluation\n",
    "## Metric Definition\n",
    "You will be assessing code smell detection quality, which measures how accurately the system identifies:\n",
    "1. The correct type of code smell\n",
    "2. The correct location of the smell (file, line numbers, method)\n",
    "\n",
    "## Criteria\n",
    "Smell Type Accuracy: The detected smell type matches the actual smell type in the code.\n",
    "Location Accuracy: The location identified for the smell (line numbers, method, class) matches where the smell actually exists.\n",
    "Justification Quality: The explanation provided for the smell makes sense and correctly describes the issue.\n",
    "Refactoring Relevance: The suggested refactoring is appropriate for the identified smell.\n",
    "\n",
    "## Rating Rubric\n",
    "EXCELLENT: Perfect match of smell type and exact location (score: 5).\n",
    "GOOD: Correct smell type with minor location imprecision (score: 4).\n",
    "ACCEPTABLE: Partial match (either correct smell type or approximate location) (score: 3).\n",
    "POOR: Wrong smell type but area of concern correctly identified (score: 2).\n",
    "INCORRECT: Completely incorrect detection (wrong smell type and location) (score: 1).\n",
    "\n",
    "## Evaluation Steps\n",
    "STEP 1: For each detected smell, find any matching ground truth smells.\n",
    "STEP 2: Evaluate the accuracy of the detected smell type.\n",
    "STEP 3: Evaluate the precision of the location identified.\n",
    "STEP 4: Assign a score based on the rating rubric.\n",
    "STEP 5: Calculate overall precision and recall metrics.\n",
    "\n",
    "# Input Data\n",
    "## Ground Truth Smells\n",
    "{ground_truth}\n",
    "\n",
    "## Detected Smells\n",
    "{detected_smells}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "# 3. Create the evaluation parser and prompt\n",
    "eval_parser = PydanticOutputParser(pydantic_object=CodeSmellEvaluationResult)\n",
    "eval_prompt = PromptTemplate(\n",
    "    template=eval_template,\n",
    "    input_variables=[\"ground_truth\", \"detected_smells\"],\n",
    "    partial_variables={\"format_instructions\": eval_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# 4. Create the evaluation function\n",
    "def evaluate_smell_detection(ground_truth_data, detected_smells, llm):\n",
    "    \"\"\"\n",
    "    Evaluate the quality of code smell detection by comparing with ground truth.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth_data: Dictionary with ground truth smells\n",
    "        detected_smells: Dictionary with detected smells\n",
    "        llm: LangChain LLM instance\n",
    "    \n",
    "    Returns:\n",
    "        Evaluation results with scores and metrics\n",
    "    \"\"\"\n",
    "    # Convert data to JSON strings\n",
    "    ground_truth_str = json.dumps(ground_truth_data, indent=2)\n",
    "    detected_str = json.dumps(detected_smells, indent=2)\n",
    "    \n",
    "    # Format the prompt\n",
    "    formatted_prompt = eval_prompt.format(\n",
    "        ground_truth=ground_truth_str,\n",
    "        detected_smells=detected_str\n",
    "    )\n",
    "    \n",
    "    # Get response from LLM\n",
    "    try:\n",
    "        output = llm.invoke(formatted_prompt)\n",
    "        parsed_output = eval_parser.parse(output.content)\n",
    "        return parsed_output\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        print(f\"Raw output: {output.content if 'output' in locals() else 'No output'}\")\n",
    "        return None\n",
    "\n",
    "# 5. Helper function to create ground truth dataset\n",
    "def create_ground_truth(file_path, manual_annotations):\n",
    "    \"\"\"Create ground truth data structure\"\"\"\n",
    "    return {\n",
    "        \"file_path\": file_path,\n",
    "        \"smells\": manual_annotations\n",
    "    }\n",
    "\n",
    "# 6. Main evaluation function\n",
    "def evaluate_code_analysis(file_path, manual_annotations, llm):\n",
    "    \"\"\"Run a full evaluation on a code file\"\"\"\n",
    "    # Get the code content\n",
    "    with open(file_path, 'r') as f:\n",
    "        code_content = f.read()\n",
    "    \n",
    "    # Run code smell detection\n",
    "    analysis_result = analyze_code_with_structure(code_content)\n",
    "    \n",
    "    if not analysis_result:\n",
    "        print(\"Failed to analyze code\")\n",
    "        return None\n",
    "    \n",
    "    # Format detected smells\n",
    "    detected_smells = {\n",
    "        \"file_path\": file_path,\n",
    "        \"smells\": []\n",
    "    }\n",
    "    \n",
    "    for smell in analysis_result.smells_detected:\n",
    "        detected_smells[\"smells\"].append({\n",
    "            \"smell_type\": smell.smell_type,\n",
    "            \"location\": smell.location,\n",
    "            \"description\": smell.description,\n",
    "            \"severity\": str(smell.severity),\n",
    "            \"refactoring\": smell.refactoring_suggestion\n",
    "        })\n",
    "    \n",
    "    # Create ground truth\n",
    "    ground_truth = create_ground_truth(file_path, manual_annotations)\n",
    "    \n",
    "    # Run evaluation\n",
    "    evaluation = evaluate_smell_detection(ground_truth, detected_smells, llm)\n",
    "    \n",
    "    # Display results\n",
    "    if evaluation:\n",
    "        print(f\"Overall Score: {evaluation.overall_score:.2f}/5.0\")\n",
    "        print(f\"Precision: {evaluation.precision:.2f}\")\n",
    "        print(f\"Recall: {evaluation.recall:.2f}\")\n",
    "        print(f\"\\nSummary: {evaluation.summary}\\n\")\n",
    "        \n",
    "        print(\"Individual Evaluations:\")\n",
    "        for i, eval_item in enumerate(evaluation.evaluations, 1):\n",
    "            print(f\"\\n{i}. {eval_item.detected_smell} ({eval_item.location})\")\n",
    "            print(f\"   Score: {eval_item.score.value}\")\n",
    "            print(f\"   Matched with: {eval_item.ground_truth_match if eval_item.ground_truth_match else 'No match'}\")\n",
    "            print(f\"   Justification: {eval_item.justification}\")\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:22.050271Z",
     "iopub.status.busy": "2025-04-21T04:13:22.049962Z",
     "iopub.status.idle": "2025-04-21T04:13:43.942881Z",
     "shell.execute_reply": "2025-04-21T04:13:43.942131Z",
     "shell.execute_reply.started": "2025-04-21T04:13:22.050245Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score: 3.00/5.0\n",
      "Precision: 0.50\n",
      "Recall: 0.14\n",
      "\n",
      "Summary: The tool correctly identified one LONG_METHOD smell, but its location was slightly off. The second detection was a false positive (LARGE_CLASS). This results in a low recall and moderate precision.\n",
      "\n",
      "Individual Evaluations:\n",
      "\n",
      "1. LONG_METHOD (HallsLevel.java, decorate method, lines 40-58)\n",
      "   Score: ACCEPTABLE\n",
      "   Matched with: decorate() method, lines 74-101\n",
      "   Justification: The smell type is correct. The location is imprecise, but the method is correctly identified. The line numbers are off, as the detected lines (40-58) do not align with the ground truth (74-101), but it points to the correct method.\n",
      "\n",
      "2. LARGE_CLASS (HallsLevel.java, entire class)\n",
      "   Score: INCORRECT\n",
      "   Matched with: No match\n",
      "   Justification: The detected smell is incorrect. There is no ground truth for LARGE_CLASS in the provided data. While the class might be doing a lot, it doesn't clearly violate the single responsibility principle to the point of being a Large Class smell according to best practices. The suggested refactoring is generic and might not be necessary.\n"
     ]
    }
   ],
   "source": [
    "# Example ground truth data for a file - here we can utilize data from static analyzers such as Sonarqube etc.\n",
    "evaluation_files = {\n",
    "    \"pixel-dungeon/src/com/watabou/pixeldungeon/levels/HallsLevel.java\": [\n",
    "        {\n",
    "            \"smell_type\": \"MAGIC_NUMBER\",\n",
    "            \"location\": \"multiple locations: lines 25-26, 37, 52-53, 85, 89\",\n",
    "            \"severity\": \"MEDIUM\"\n",
    "        },\n",
    "        {\n",
    "            \"smell_type\": \"LONG_METHOD\",\n",
    "            \"location\": \"decorate() method, lines 74-101\",\n",
    "            \"severity\": \"MEDIUM\"\n",
    "        },\n",
    "        {\n",
    "            \"smell_type\": \"CONDITIONAL_COMPLEXITY\",\n",
    "            \"location\": \"decorate() method, lines 76-89\",\n",
    "            \"severity\": \"LOW\"\n",
    "        },\n",
    "        {\n",
    "            \"smell_type\": \"DUPLICATED_CODE\",\n",
    "            \"location\": \"tileName() and tileDesc() methods, lines 104-138\",\n",
    "            \"severity\": \"LOW\"\n",
    "        },\n",
    "        {\n",
    "            \"smell_type\": \"DEAD_CODE\",\n",
    "            \"location\": \"map[i] == 63 condition in addVisuals method, line 151\",\n",
    "            \"severity\": \"MEDIUM\"\n",
    "        },\n",
    "        {\n",
    "            \"smell_type\": \"FEATURE_ENVY\",\n",
    "            \"location\": \"addVisuals method, lines 149-153\",\n",
    "            \"severity\": \"LOW\"\n",
    "        },\n",
    "        {\n",
    "            \"smell_type\": \"PRIMITIVE_OBSESSION\",\n",
    "            \"location\": \"throughout class, using boolean arrays and ints for terrain\",\n",
    "            \"severity\": \"LOW\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Run evaluation on a single file\n",
    "java_file = \"pixel-dungeon/src/com/watabou/pixeldungeon/levels/HallsLevel.java\"\n",
    "evaluation = evaluate_code_analysis(java_file, evaluation_files, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T04:13:43.944167Z",
     "iopub.status.busy": "2025-04-21T04:13:43.943699Z",
     "iopub.status.idle": "2025-04-21T04:14:11.397658Z",
     "shell.execute_reply": "2025-04-21T04:14:11.396829Z",
     "shell.execute_reply.started": "2025-04-21T04:13:43.944144Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating pixel-dungeon/src/com/watabou/pixeldungeon/levels/HallsLevel.java ===\n",
      "Overall Score: 3.00/5.0\n",
      "Precision: 0.50\n",
      "Recall: 0.14\n",
      "\n",
      "Summary: The code smell detection identified one LONG_METHOD smell with approximate location accuracy and incorrectly identified a LARGE_CLASS smell. The overall precision is 0.5, and the recall is 0.14285714285714285.\n",
      "\n",
      "Individual Evaluations:\n",
      "\n",
      "1. LONG_METHOD (HallsLevel.java, decorate() method, lines 50-74)\n",
      "   Score: ACCEPTABLE\n",
      "   Matched with: LONG_METHOD\n",
      "   Justification: The detected smell type is correct (LONG_METHOD), and the location is approximately correct. The ground truth location is lines 74-101, while the detected location is 50-74. There is overlap, but it is not a perfect match.\n",
      "\n",
      "2. LARGE_CLASS (HallsLevel.java, entire class)\n",
      "   Score: INCORRECT\n",
      "   Matched with: No match\n",
      "   Justification: There is no LARGE_CLASS smell in the ground truth for HallsLevel.java. While the class may have multiple responsibilities, it's not explicitly identified as a LARGE_CLASS. The detected smell is incorrect.\n",
      "\n",
      "=== OVERALL EVALUATION ===\n",
      "Average Score: 3.00/5.0\n",
      "Average Precision: 0.50\n",
      "Average Recall: 0.14\n"
     ]
    }
   ],
   "source": [
    "# Run evaluations and collect results\n",
    "results = {}\n",
    "for file_path, annotations in evaluation_files.items():\n",
    "    print(f\"\\n=== Evaluating {file_path} ===\")\n",
    "    eval_result = evaluate_code_analysis(file_path, annotations, llm)\n",
    "    if eval_result:\n",
    "        results[file_path] = eval_result\n",
    "\n",
    "# Calculate overall metrics\n",
    "if results:\n",
    "    total_score = sum(result.overall_score for result in results.values())\n",
    "    avg_score = total_score / len(results)\n",
    "    avg_precision = sum(result.precision for result in results.values()) / len(results)\n",
    "    avg_recall = sum(result.recall for result in results.values()) / len(results)\n",
    "\n",
    "    print(\"\\n=== OVERALL EVALUATION ===\")\n",
    "    print(f\"Average Score: {avg_score:.2f}/5.0\")\n",
    "    print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Read the token securely from environment variable\n",
    "sonar-scanner \\\n",
    "  -Dsonar.projectKey=arthas \\\n",
    "  -Dsonar.sources=. \\\n",
    "  -Dsonar.host.url=http://localhost:9000 \\\n",
    "  -Dsonar.token=${SONARQUBE_TOKEN} \\\n",
    "  -Dsonar.java.binaries=. \\\n",
    "  -Dsonar.language=java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "class CodeSmellLocation:\n",
    "    def __init__(self, start_line: int, end_line: int, start_offset: int, end_offset: int):\n",
    "        self.start_line = start_line\n",
    "        self.end_line = end_line\n",
    "        self.start_offset = start_offset\n",
    "        self.end_offset = end_offset\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Lines {self.start_line}-{self.end_line}\"\n",
    "    \n",
    "    @classmethod\n",
    "    def from_text_range(cls, text_range: Dict):\n",
    "        return cls(\n",
    "            text_range.get(\"startLine\", 0),\n",
    "            text_range.get(\"endLine\", 0),\n",
    "            text_range.get(\"startOffset\", 0),\n",
    "            text_range.get(\"endOffset\", 0)\n",
    "        )\n",
    "\n",
    "class Impact:\n",
    "    def __init__(self, quality: str, severity: str):\n",
    "        self.quality = quality  # e.g., \"SECURITY\", \"MAINTAINABILITY\"\n",
    "        self.severity = severity  # e.g., \"HIGH\", \"MEDIUM\", \"LOW\"\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.quality} ({self.severity})\"\n",
    "\n",
    "class CodeSmell:\n",
    "    def __init__(self, \n",
    "                 issue_key: str,\n",
    "                 rule_key: str,\n",
    "                 message: str,\n",
    "                 component: str,\n",
    "                 location: CodeSmellLocation,\n",
    "                 impacts: List[Impact],\n",
    "                 effort: Optional[str] = None,\n",
    "                 rule_name: Optional[str] = None,\n",
    "                 file_path: Optional[str] = None,\n",
    "                 clean_code_attribute: Optional[str] = None,\n",
    "                 author: Optional[str] = None):\n",
    "        self.issue_key = issue_key\n",
    "        self.rule_key = rule_key\n",
    "        self.rule_name = rule_name\n",
    "        self.message = message\n",
    "        self.component = component\n",
    "        self.file_path = file_path\n",
    "        self.location = location\n",
    "        self.impacts = impacts\n",
    "        self.effort = effort\n",
    "        self.clean_code_attribute = clean_code_attribute\n",
    "        self.author = author\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        impacts_str = \", \".join(str(impact) for impact in self.impacts)\n",
    "        return (f\"Code Smell: {self.rule_name} ({self.rule_key})\\n\"\n",
    "                f\"Location: {self.location}, File: {self.file_path or self.component}\\n\"\n",
    "                f\"Message: {self.message}\\n\"\n",
    "                f\"Impacts: {impacts_str}\\n\"\n",
    "                f\"Effort: {self.effort or 'Unknown'}\")\n",
    "\n",
    "def parse_sonarqube_code_smells(json_data: Dict) -> List[CodeSmell]:\n",
    "    \"\"\"Parse SonarQube API response and extract code smell information\"\"\"\n",
    "    \n",
    "    # Create lookup dictionaries for rules and components\n",
    "    rules_dict = {rule[\"key\"]: rule for rule in json_data.get(\"rules\", [])}\n",
    "    components_dict = {comp[\"key\"]: comp for comp in json_data.get(\"components\", [])}\n",
    "    \n",
    "    code_smells = []\n",
    "    \n",
    "    for issue in json_data.get(\"issues\", []):\n",
    "        # Extract rule information\n",
    "        rule_key = issue.get(\"rule\")\n",
    "        rule_info = rules_dict.get(rule_key, {})\n",
    "        rule_name = rule_info.get(\"name\")\n",
    "        \n",
    "        # Extract component information\n",
    "        component_key = issue.get(\"component\")\n",
    "        component_info = components_dict.get(component_key, {})\n",
    "        file_path = component_info.get(\"path\") or component_info.get(\"longName\")\n",
    "        \n",
    "        # Extract location\n",
    "        location = CodeSmellLocation.from_text_range(issue.get(\"textRange\", {\n",
    "            \"startLine\": issue.get(\"line\", 0),\n",
    "            \"endLine\": issue.get(\"line\", 0),\n",
    "            \"startOffset\": 0,\n",
    "            \"endOffset\": 0\n",
    "        }))\n",
    "        \n",
    "        # Extract impacts\n",
    "        impacts = [Impact(impact.get(\"softwareQuality\", \"\"), impact.get(\"severity\", \"\"))\n",
    "                  for impact in issue.get(\"impacts\", [])]\n",
    "        \n",
    "        # Create CodeSmell object\n",
    "        code_smell = CodeSmell(\n",
    "            issue_key=issue.get(\"key\", \"\"),\n",
    "            rule_key=rule_key,\n",
    "            rule_name=rule_name,\n",
    "            message=issue.get(\"message\", \"\"),\n",
    "            component=component_key,\n",
    "            file_path=file_path,\n",
    "            location=location,\n",
    "            impacts=impacts,\n",
    "            effort=issue.get(\"effort\"),\n",
    "            clean_code_attribute=issue.get(\"cleanCodeAttribute\"),\n",
    "            author=issue.get(\"author\")\n",
    "        )\n",
    "        \n",
    "        code_smells.append(code_smell)\n",
    "    \n",
    "    return code_smells\n",
    "\n",
    "# Example usage:\n",
    "def process_sonarqube_response(json_string: str):\n",
    "    data = json.loads(json_string)\n",
    "    code_smells = parse_sonarqube_code_smells(data)\n",
    "    \n",
    "    print(f\"Found {len(code_smells)} code smells:\")\n",
    "    for i, smell in enumerate(code_smells, 1):\n",
    "        print(f\"\\n{i}. {smell}\")\n",
    "    \n",
    "    return code_smells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"total\": 1,\n",
      "  \"p\": 1,\n",
      "  \"ps\": 50,\n",
      "  \"paging\": {\n",
      "    \"pageIndex\": 1,\n",
      "    \"pageSize\": 50,\n",
      "    \"total\": 1\n",
      "  },\n",
      "  \"effortTotal\": 20,\n",
      "  \"issues\": [\n",
      "    {\n",
      "      \"key\": \"53ef6fab-71bd-4e51-a221-1f1b25e23003\",\n",
      "      \"rule\": \"java:S107\",\n",
      "      \"severity\": \"MAJOR\",\n",
      "      \"component\": \"arthas:core/src/main/java/com/taobao/arthas/core/advisor/Advice.java\",\n",
      "      \"project\": \"arthas\",\n",
      "      \"line\": 71,\n",
      "      \"hash\": \"64e96bf261dd6801924266f9bdc8278a\",\n",
      "      \"textRange\": {\n",
      "        \"startLine\": 71,\n",
      "        \"endLine\": 71,\n",
      "        \"startOffset\": 12,\n",
      "        \"endOffset\": 18\n",
      "      },\n",
      "      \"flows\": [],\n",
      "      \"status\": \"OPEN\",\n",
      "      \"message\": \"Constructor has 8 parameters, which is greater than 7 authorized.\",\n",
      "      \"effort\": \"20min\",\n",
      "      \"debt\": \"20min\",\n",
      "      \"author\": \"hengyunabc@gmail.com\",\n",
      "      \"tags\": [\n",
      "        \"brain-overload\"\n",
      "      ],\n",
      "      \"creationDate\": \"2018-08-31T03:49:48+0000\",\n",
      "      \"updateDate\": \"2025-05-15T22:28:08+0000\",\n",
      "      \"type\": \"CODE_SMELL\",\n",
      "      \"scope\": \"MAIN\",\n",
      "      \"quickFixAvailable\": false,\n",
      "      \"messageFormattings\": [],\n",
      "      \"codeVariants\": [],\n",
      "      \"cleanCodeAttribute\": \"FOCUSED\",\n",
      "      \"cleanCodeAttributeCategory\": \"ADAPTABLE\",\n",
      "      \"impacts\": [\n",
      "        {\n",
      "          \"softwareQuality\": \"MAINTAINABILITY\",\n",
      "          \"severity\": \"MEDIUM\"\n",
      "        }\n",
      "      ],\n",
      "      \"issueStatus\": \"OPEN\",\n",
      "      \"prioritizedRule\": false\n",
      "    }\n",
      "  ],\n",
      "  \"components\": [\n",
      "    {\n",
      "      \"key\": \"arthas\",\n",
      "      \"enabled\": true,\n",
      "      \"qualifier\": \"TRK\",\n",
      "      \"name\": \"arthas\",\n",
      "      \"longName\": \"arthas\"\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"arthas:core/src/main/java/com/taobao/arthas/core/advisor/Advice.java\",\n",
      "      \"enabled\": true,\n",
      "      \"qualifier\": \"FIL\",\n",
      "      \"name\": \"Advice.java\",\n",
      "      \"longName\": \"core/src/main/java/com/taobao/arthas/core/advisor/Advice.java\",\n",
      "      \"path\": \"core/src/main/java/com/taobao/arthas/core/advisor/Advice.java\"\n",
      "    }\n",
      "  ],\n",
      "  \"facets\": []\n",
      "}\n",
      "Successfully retrieved code smells from SonarQube.\n",
      "Found 1 code smells:\n",
      "\n",
      "1. Code Smell: None (java:S107)\n",
      "Location: Lines 71-71, File: core/src/main/java/com/taobao/arthas/core/advisor/Advice.java\n",
      "Message: Constructor has 8 parameters, which is greater than 7 authorized.\n",
      "Impacts: MAINTAINABILITY (MEDIUM)\n",
      "Effort: 20min\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from enum import Enum\n",
    "\n",
    "# Create a mapping between code smells and SonarQube rule IDs\n",
    "class SonarQubeSmellRule(Enum):\n",
    "    LONG_PARAMETER_LIST = \"java:S107\"  # Methods should not have too many parameters\n",
    "    LONG_METHOD = \"java:S138\"         # Methods should not have too many lines\n",
    "    COMPLEX_METHOD = \"java:S3776\"     # Cognitive Complexity of methods should not be too high\n",
    "    LARGE_CLASS = \"java:S1448\"        # Classes should not have too many lines\n",
    "    DUPLICATED_CODE = \"java:S1192\"    # String literals should not be duplicated\n",
    "\n",
    "# Helper function to get rule string from smell type(s)\n",
    "def get_rule_string(smells):\n",
    "    if isinstance(smells, SonarQubeSmellRule):\n",
    "        return smells.value\n",
    "    elif isinstance(smells, list):\n",
    "        return \", \".join([smell.value for smell in smells])\n",
    "    else:\n",
    "        raise ValueError(\"Smells must be a SonarQubeSmellRule or list of SonarQubeSmellRule\")\n",
    "\n",
    "# Configuration\n",
    "sonar_url = \"http://localhost:9000\"  # SonarQube server URL\n",
    "sonar_user_token = \"squ_5f531b81a0c5bc427a57c61d10c26c69a58b67d3\"\n",
    "project_key = \"arthas\"\n",
    "\n",
    "# API endpoint for issues search\n",
    "url = f\"{sonar_url}/api/issues/search\"\n",
    "\n",
    "# Choose which smell to look for\n",
    "target_smell = SonarQubeSmellRule.LONG_PARAMETER_LIST\n",
    "# Or use multiple smells: target_smells = [SonarQubeSmellRule.LONG_PARAMETER_LIST, SonarQubeSmellRule.LONG_METHOD]\n",
    "\n",
    "# Parameters to get only code smells\n",
    "params = {\n",
    "    \"componentKeys\": project_key,\n",
    "    \"types\": \"CODE_SMELL\",\n",
    "    \"rules\": get_rule_string(target_smell),\n",
    "    \"ps\": 50  # page size (max 500)\n",
    "}\n",
    "\n",
    "# Authentication with token\n",
    "auth = (sonar_user_token, \"\")\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(url, params=params, auth=auth)\n",
    "code_smells = response.json()\n",
    "print(json.dumps(code_smells, indent=2))\n",
    "\n",
    "# Process results\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully retrieved code smells from SonarQube.\")\n",
    "    # Handle pagination if needed (total > 500)\n",
    "    total = process_sonarqube_response(json.dumps(code_smells, indent=2))\n",
    "else:\n",
    "    print(f\"Error retrieving code smells: {response.status_code}\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 10 samples with smells\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>designite_id</th>\n",
       "      <th>has_smell</th>\n",
       "      <th>is_class</th>\n",
       "      <th>path_to_file</th>\n",
       "      <th>project_name</th>\n",
       "      <th>sample_constraints</th>\n",
       "      <th>smells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2386</td>\n",
       "      <td>538</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2387</td>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2406</td>\n",
       "      <td>532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2407</td>\n",
       "      <td>536</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2494</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2501</td>\n",
       "      <td>5129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2551</td>\n",
       "      <td>5487</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2567</td>\n",
       "      <td>5480</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2569</td>\n",
       "      <td>5479</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2577</td>\n",
       "      <td>5441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/Blankj_AndroidUtilCode/...</td>\n",
       "      <td>Blankj_AndroidUtilCode</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  designite_id  has_smell  is_class  \\\n",
       "0  2386           538          1         0   \n",
       "1  2387           542          1         0   \n",
       "2  2406           532          1         0   \n",
       "3  2407           536          1         0   \n",
       "4  2494           552          1         0   \n",
       "5  2501          5129          1         0   \n",
       "6  2551          5487          1         0   \n",
       "7  2567          5480          1         0   \n",
       "8  2569          5479          1         0   \n",
       "9  2577          5441          1         0   \n",
       "\n",
       "                                        path_to_file            project_name  \\\n",
       "0  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "1  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "2  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "3  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "4  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "5  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "6  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "7  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "8  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "9  /codesplit_java_method/Blankj_AndroidUtilCode/...  Blankj_AndroidUtilCode   \n",
       "\n",
       "   sample_constraints smells  \n",
       "0                   5      2  \n",
       "1                   6      2  \n",
       "2                   9      2  \n",
       "3                   7      2  \n",
       "4                   3      2  \n",
       "5                   3      2  \n",
       "6                   3      2  \n",
       "7                   3      2  \n",
       "8                   3      2  \n",
       "9                   3      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accessing first row:\n",
      "File path: /codesplit_java_method/Blankj_AndroidUtilCode/Blankj_AndroidUtilCode/com.blankj.subutil.util/ContentProvider4SubUtil/query.code\n",
      "Project name: Blankj_AndroidUtilCode\n",
      "Has smell: Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"dacos\"\n",
    ")\n",
    "\n",
    "# Create cursor and run queries\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT id, designite_id, has_smell, is_class, path_to_file, project_name, sample_constraints, smells FROM tagman5.sample WHERE smells IN (2) LIMIT 10\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "column_names = [column[0] for column in cursor.description]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "print(f\"Retrieved {len(df)} samples with smells\")\n",
    "display(df)\n",
    "\n",
    "if len(df) > 0:\n",
    "    print(\"\\nAccessing first row:\")\n",
    "    print(f\"File path: {df.iloc[0]['path_to_file']}\")\n",
    "    print(f\"Project name: {df.iloc[0]['project_name']}\")\n",
    "    print(f\"Has smell: {'Yes' if df.iloc[0]['has_smell'] else 'No'}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 10 samples with smells\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>designite_id</th>\n",
       "      <th>has_smell</th>\n",
       "      <th>is_class</th>\n",
       "      <th>path_to_file</th>\n",
       "      <th>project_name</th>\n",
       "      <th>sample_constraints</th>\n",
       "      <th>smells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44635</td>\n",
       "      <td>59787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44787</td>\n",
       "      <td>63642</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44917</td>\n",
       "      <td>59836</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44951</td>\n",
       "      <td>59902</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44998</td>\n",
       "      <td>59960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45029</td>\n",
       "      <td>59926</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45044</td>\n",
       "      <td>59981</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45061</td>\n",
       "      <td>59814</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45136</td>\n",
       "      <td>59195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45155</td>\n",
       "      <td>59172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/codesplit_java_method/alibaba_arthas/alibaba_...</td>\n",
       "      <td>alibaba_arthas</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  designite_id  has_smell  is_class  \\\n",
       "0  44635         59787          1         0   \n",
       "1  44787         63642          1         0   \n",
       "2  44917         59836          1         0   \n",
       "3  44951         59902          1         0   \n",
       "4  44998         59960          1         0   \n",
       "5  45029         59926          1         0   \n",
       "6  45044         59981          1         0   \n",
       "7  45061         59814          1         0   \n",
       "8  45136         59195          1         0   \n",
       "9  45155         59172          1         0   \n",
       "\n",
       "                                        path_to_file    project_name  \\\n",
       "0  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "1  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "2  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "3  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "4  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "5  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "6  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "7  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "8  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "9  /codesplit_java_method/alibaba_arthas/alibaba_...  alibaba_arthas   \n",
       "\n",
       "   sample_constraints smells  \n",
       "0                   2      2  \n",
       "1                   2      2  \n",
       "2                   2      2  \n",
       "3                   2      2  \n",
       "4                   2      2  \n",
       "5                   2      2  \n",
       "6                   2      2  \n",
       "7                   2      2  \n",
       "8                   2      2  \n",
       "9                   2      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accessing first row:\n",
      "File path: /codesplit_java_method/alibaba_arthas/alibaba_arthas/com.taobao.arthas.core.command.express/ArthasObjectPropertyAccessor/setPossibleProperty.code\n",
      "Project name: alibaba_arthas\n",
      "Has smell: Yes\n",
      "/codesplit_java_method/alibaba_arthas/alibaba_arthas/com.taobao.arthas.core.command.express/ArthasObjectPropertyAccessor setPossibleProperty.code\n",
      "\n",
      "New file path (with .java): /codesplit_java_method/alibaba_arthas/alibaba_arthas/com.taobao.arthas.core.command.express/ArthasObjectPropertyAccessor/setPossibleProperty.java\n",
      "\n",
      "File not found: /codesplit_java_method/alibaba_arthas/alibaba_arthas/com.taobao.arthas.core.command.express/ArthasObjectPropertyAccessor/setPossibleProperty.java\n",
      "Please check if the path is correct.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Connect to MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"dacos\"\n",
    ")\n",
    "\n",
    "# Create cursor and run queries\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT id, designite_id, has_smell, is_class, path_to_file, project_name, sample_constraints, smells FROM tagman5.sample\" \\\n",
    "\" WHERE smells IN (2) AND project_name='alibaba_arthas' LIMIT 10\")\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "column_names = [column[0] for column in cursor.description]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "print(f\"Retrieved {len(df)} samples with smells\")\n",
    "display(df)\n",
    "\n",
    "if len(df) > 0:\n",
    "    print(\"\\nAccessing first row:\")\n",
    "    file_path = df.iloc[0]['path_to_file']\n",
    "    print(f\"File path: {file_path}\")\n",
    "    print(f\"Project name: {df.iloc[0]['project_name']}\")\n",
    "    print(f\"Has smell: {'Yes' if df.iloc[0]['has_smell'] else 'No'}\")\n",
    "    \n",
    "    # Construct new file path with .java extension\n",
    "    dir_name, file_name = os.path.split(file_path)\n",
    "    print(dir_name, file_name)\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    new_file_path = os.path.join(dir_name, base_name + \".java\")\n",
    "    \n",
    "    print(f\"\\nNew file path (with .java): {new_file_path}\")\n",
    "    \n",
    "    # Analyze the code using the function defined in previous cells\n",
    "    try:\n",
    "        # First check if the file exists\n",
    "        if os.path.exists(new_file_path):\n",
    "            # Use display_code_analysis which is already defined\n",
    "            print(f\"\\nAnalyzing code in: {new_file_path}\")\n",
    "            display_code_analysis(new_file_path)\n",
    "        else:\n",
    "            print(f\"\\nFile not found: {new_file_path}\")\n",
    "            print(\"Please check if the path is correct.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError analyzing file: {e}\")\n",
    "        \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 97258,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
